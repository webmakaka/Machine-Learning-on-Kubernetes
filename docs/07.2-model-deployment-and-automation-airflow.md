# [OK!] Chapter 7. Model Deployment and Automation

<br/>

### Prepare Github

// Create an empty repo with main branch  
https://github.com/wildmakaka/airflow-dags

<br/>

Github -> Settings -> Developer Settings -> Personal access tokens -> Tokens (classic) -> Generate new token (classic)

Name: AIRFLOW

Generate Token

<br/>

```
$ kubectl edit kfdef opendatahub-ml-workshop -n ml-workshop
```

<br/>

```
$ kubectl get deployment app-aflow-airflow-scheduler -o yaml -n ml-workshop | grep value:.*airflow-dags.git
```

<br/>

### Apache Airflow

<br/>

```
$ kubectl get pods -n ml-workshop | grep airflow
app-aflow-airflow-scheduler-55d99b6f5f-p47tb                   2/2     Running     10 (105m ago)   23h
app-aflow-airflow-web-8699fdd879-zhwbh                         2/2     Running     7 (105m ago)    23h
app-aflow-airflow-worker-0                                     2/2     Running     10 (33m ago)    23h
```

<br/>

```
$ kubectl get ingress -n ml-workshop | grep airflow
ap-airflow2            nginx   airflow.192.168.49.2.nip.io      192.168.49.2   80, 443   23h
```

<br/>

```
https://airflow.192.168.49.2.nip.io
```

<br/>

### Configuring Airflow runtime images

<br/>

https://jupyterhub.192.168.49.2.nip.io/

<br/>

```
Image: SciKit v.1.10 - Elyra Notebook Image
Container size: Small

Variable name: AWS_SECRET_ACCESS_KEY
Variable value: minio123

Secret: no
```

<br/>

Machine-Learning-on-Kubernetes/Chapter07.03/model_deploy_pipeline/

<br/>

File -> New -> Pipeline Editor

Rename hello_world.pipeline

<br/>

File > New Python File

Create 2 file

hello.py and world.py

<br/>

Witch content:

```python
print('Hello Script AirFlow!')
```

```python
print('World Script AirFlow!')
```

<br/>

Drag files on hello_world.pipeline

Add arrow from hello.py to world.py

<br/>

### Runtime Images (left) -> Add

<br/>

```
Name: Kaniko Container Builder

Description: A Kaniko container for building

Source: quay.io/ml-on-k8s/kaniko-container-builder:1.0.0

Image Pull Policy: IfNotPresent

SAVE & CLOSE
```

<br/>

```
Name: Airflow Python Runner

Description: A container with Python runtime

Source: quay.io/ml-on-k8s/airflow-python-runner:0.0.11

Image Pull Policy: IfNotPresent

SAVE & CLOSE
```

<br/>

Reopen pipeline hello_world.pipeline to update

```
hello.py -> Runtime Image: Kaniko Container Builder
world.py -> Runtime Image: Airflow Python Runner
```

<br/>

### Run

Runtimes (left) + New Apache Airflow runtime

<br/>

```
Name: MyAirflow
Description: MyAirflow

Apache Airflow UI Endpoint: https://airflow.192.168.49.2.nip.io
Apache Airflow User Namespace: ml-workshop
Github API Endpoint: https://api.github.com
GitHub DAG Repository: wildmakaka/airflow-dags
GitHub DAG Repository Branch: main
Github Personal Access Token: [YOUR_GITHUB_TOKEN]

Cloud Object Storage Endpoint: http://minio-ml-workshop:9000
Cloud Object Storage Credential Secret: [empty]
Cloud Object Storage Username: minio
Cloud Object Storage Password: minio123
Cloud Object Storage Bucket Name: airflow
```

<br/>

```
run Button "Play"

Pipeline Name: hello_world
Runtime Platform: Apache Airflow runtime
Runtime Configuration: MyAirflow
```

<br/>

[Success!]

New python script appeared in  
https://github.com/wildmakaka/airflow-dags/tree/main

<br/>

// DAG appears  
https://airflow.192.168.49.2.nip.io/home

<br/>

// Logs Appeared in airflow storage  
https://minio.192.168.49.2.nip.io/
